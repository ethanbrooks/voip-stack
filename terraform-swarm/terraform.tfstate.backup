{
  "version": 4,
  "terraform_version": "0.12.26",
  "serial": 89,
  "lineage": "85c8dda0-fb5c-0a77-3ee0-ea2a7a6c8c0b",
  "outputs": {
    "daemon_cert_request_pems": {
      "value": [],
      "type": [
        "tuple",
        []
      ]
    },
    "iam_role": {
      "value": "docker-swarm-ec2",
      "type": "string"
    },
    "manager_instance_ids": {
      "value": [
        "i-0fa1343dee5834fff",
        "i-005b0b45a51b649d4",
        "i-0e3603c56a73b1446"
      ],
      "type": [
        "tuple",
        [
          "string",
          "string",
          "string"
        ]
      ]
    },
    "manager_ips": {
      "value": [
        "54.224.82.117",
        "3.233.238.35",
        "54.84.238.85"
      ],
      "type": [
        "tuple",
        [
          "string",
          "string",
          "string"
        ]
      ]
    },
    "subnet_cidr_blocks": {
      "value": [
        "10.100.10.0/24",
        "10.100.11.0/24",
        "10.100.12.0/24",
        "10.100.13.0/24",
        "10.100.14.0/24",
        "10.100.15.0/24",
        "10.100.110.0/24",
        "10.100.111.0/24",
        "10.100.112.0/24",
        "10.100.113.0/24",
        "10.100.114.0/24",
        "10.100.115.0/24"
      ],
      "type": [
        "tuple",
        [
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string"
        ]
      ]
    },
    "subnet_count": {
      "value": 12,
      "type": "number"
    },
    "subnets": {
      "value": [
        "subnet-009f7db49a1b27527",
        "subnet-048f7c9eda782262a",
        "subnet-0e5abf73a4eada2bc",
        "subnet-0037169cfa4093d48",
        "subnet-0bff3e5ad68efb61d",
        "subnet-0178c58133dbfb80a",
        "subnet-07be5f3106a81967c",
        "subnet-0feeda4742873bb38",
        "subnet-0528a102948f990a9",
        "subnet-07fc208faa1109c20",
        "subnet-009df2e98043980ac",
        "subnet-0c6adf12e286bf68c"
      ],
      "type": [
        "tuple",
        [
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string",
          "string"
        ]
      ]
    },
    "worker_instance_ids": {
      "value": [
        null,
        null
      ],
      "type": [
        "tuple",
        [
          "string",
          "string"
        ]
      ]
    },
    "worker_ips": {
      "value": [
        null,
        null
      ],
      "type": [
        "tuple",
        [
          "string",
          "string"
        ]
      ]
    },
    "worker_subnets": {
      "value": [
        "subnet-07be5f3106a81967c",
        "subnet-0feeda4742873bb38",
        "subnet-0528a102948f990a9",
        "subnet-07fc208faa1109c20",
        "subnet-009df2e98043980ac",
        "subnet-0c6adf12e286bf68c"
      ],
      "type": [
        "tuple",
        [
          "string",
          "string",
          "string",
          "string",
          "string",
          "string"
        ]
      ]
    }
  },
  "resources": [
    {
      "mode": "data",
      "type": "aws_ami",
      "name": "base_ami",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "architecture": "x86_64",
            "block_device_mappings": [
              {
                "device_name": "/dev/xvda",
                "ebs": {
                  "delete_on_termination": "true",
                  "encrypted": "false",
                  "iops": "0",
                  "snapshot_id": "snap-074e8f0568ee430f1",
                  "volume_size": "8",
                  "volume_type": "standard"
                },
                "no_device": "",
                "virtual_name": ""
              }
            ],
            "creation_date": "2020-05-27T06:53:59.000Z",
            "description": "Amazon Linux 2 AMI 2.0.20200520.1 x86_64 HVM ebs",
            "executable_users": null,
            "filter": null,
            "hypervisor": "xen",
            "id": "ami-0f84e2a3635d2fac9",
            "image_id": "ami-0f84e2a3635d2fac9",
            "image_location": "amazon/amzn2-ami-hvm-2.0.20200520.1-x86_64-ebs",
            "image_owner_alias": "amazon",
            "image_type": "machine",
            "kernel_id": null,
            "most_recent": true,
            "name": "amzn2-ami-hvm-2.0.20200520.1-x86_64-ebs",
            "name_regex": "^amzn2-ami-hvm-.*-x86_64-ebs",
            "owner_id": "137112412989",
            "owners": [
              "amazon",
              "self"
            ],
            "platform": null,
            "product_codes": [],
            "public": true,
            "ramdisk_id": null,
            "root_device_name": "/dev/xvda",
            "root_device_type": "ebs",
            "root_snapshot_id": "snap-074e8f0568ee430f1",
            "sriov_net_support": "simple",
            "state": "available",
            "state_reason": {
              "code": "UNSET",
              "message": "UNSET"
            },
            "tags": {},
            "virtualization_type": "hvm"
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_availability_zones",
      "name": "azs",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "all_availability_zones": null,
            "blacklisted_names": null,
            "blacklisted_zone_ids": null,
            "filter": null,
            "group_names": [
              "us-east-1"
            ],
            "id": "2020-06-04 16:06:43.671706 +0000 UTC",
            "names": [
              "us-east-1a",
              "us-east-1b",
              "us-east-1c",
              "us-east-1d",
              "us-east-1e",
              "us-east-1f"
            ],
            "state": null,
            "zone_ids": [
              "use1-az6",
              "use1-az1",
              "use1-az2",
              "use1-az4",
              "use1-az3",
              "use1-az5"
            ]
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_eip",
      "name": "daemons",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "data",
      "type": "aws_iam_policy_document",
      "name": "instance-assume-role-policy",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "1903849331",
            "json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}",
            "override_json": null,
            "policy_id": null,
            "source_json": null,
            "statement": [
              {
                "actions": [
                  "sts:AssumeRole"
                ],
                "condition": [],
                "effect": "Allow",
                "not_actions": [],
                "not_principals": [],
                "not_resources": [],
                "principals": [
                  {
                    "identifiers": [
                      "ec2.amazonaws.com"
                    ],
                    "type": "Service"
                  }
                ],
                "resources": [],
                "sid": ""
              }
            ],
            "version": "2012-10-17"
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_iam_policy_document",
      "name": "s3-access-role-policy",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "1588035595",
            "json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:PutObject\",\n        \"s3:ListBucket\",\n        \"s3:GetObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::docker-swarm.terraform/*\",\n        \"arn:aws:s3:::docker-swarm.terraform\"\n      ]\n    },\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:DescribeVpcs\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:DescribeInstances\",\n        \"ec2:DeleteTags\",\n        \"ec2:CreateTags\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}",
            "override_json": null,
            "policy_id": null,
            "source_json": null,
            "statement": [
              {
                "actions": [
                  "s3:DeleteObject",
                  "s3:GetObject",
                  "s3:ListBucket",
                  "s3:PutObject"
                ],
                "condition": [],
                "effect": "Allow",
                "not_actions": [],
                "not_principals": [],
                "not_resources": [],
                "principals": [],
                "resources": [
                  "arn:aws:s3:::docker-swarm.terraform",
                  "arn:aws:s3:::docker-swarm.terraform/*"
                ],
                "sid": ""
              },
              {
                "actions": [
                  "ec2:DescribeVpcs"
                ],
                "condition": [],
                "effect": "Allow",
                "not_actions": [],
                "not_principals": [],
                "not_resources": [],
                "principals": [],
                "resources": [
                  "*"
                ],
                "sid": ""
              },
              {
                "actions": [
                  "ec2:CreateTags",
                  "ec2:DeleteTags",
                  "ec2:DescribeInstances"
                ],
                "condition": [],
                "effect": "Allow",
                "not_actions": [],
                "not_principals": [],
                "not_resources": [],
                "principals": [],
                "resources": [
                  "*"
                ],
                "sid": ""
              }
            ],
            "version": "2012-10-17"
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_region",
      "name": "current",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "current": null,
            "description": "US East (N. Virginia)",
            "endpoint": "ec2.us-east-1.amazonaws.com",
            "id": "us-east-1",
            "name": "us-east-1"
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "aws_vpc",
      "name": "main",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:vpc/vpc-08e7f421041da4651",
            "cidr_block": "10.100.0.0/16",
            "cidr_block_associations": [
              {
                "association_id": "vpc-cidr-assoc-019746bdaddfac09b",
                "cidr_block": "10.100.0.0/16",
                "state": "associated"
              }
            ],
            "default": false,
            "dhcp_options_id": "dopt-6df33417",
            "enable_dns_hostnames": true,
            "enable_dns_support": true,
            "filter": null,
            "id": "vpc-08e7f421041da4651",
            "instance_tenancy": "default",
            "ipv6_association_id": "vpc-cidr-assoc-0157475bbdec9e744",
            "ipv6_cidr_block": "2600:1f18:368:100::/56",
            "main_route_table_id": "rtb-065c3b0815f9578e1",
            "owner_id": "569484333419",
            "state": "available",
            "tags": {
              "Name": "voip"
            }
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "cloudinit_config",
      "name": "managers",
      "each": "list",
      "provider": "provider.cloudinit",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "base64_encode": true,
            "gzip": true,
            "id": "3648404182",
            "part": [
              {
                "content": "#cloud-config\nbootcmd:\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-docker\", \"amazon-linux-extras\", \"install\", \"docker\" ]\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-epel\", \"amazon-linux-extras\", \"install\", \"epel\" ]\nrepo_update: true\nrepo_upgrade: all\npackages:\n  - docker\n  - python2-boto3\n  - yum-cron\noutput:\n  all: \"| tee -a /var/log/cloud-init-output.log\"\nmanage_resolve_conf: true\nresolve_conf:\n  name_servers: [ '169.254.169.253' ]\nruncmd:\n  - [ sysctl, -w, vm.max_map_count=262144 ]\n  - [ sysctl, -w, fs.file-max=65536 ]\n  - [ ulimit, -n, 65536 ]\n  - [ ulimit, -u, 4096 ]\nwrite_files:\n  - content: |\n      vm.max_map_count=262144\n      fs.file-max=65536\n    path: /etc/sysctl.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      *          soft    nproc     4096\n      *          soft    nofile    65536\n    path: /etc/security/limits.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      #!/bin/sh\n      docker image prune -f \u003e /dev/null\n      docker container prune -f \u003e /dev/null\n    path: /etc/cron.hourly/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker image prune --all -f \u003e /dev/null\n      docker network prune -f \u003e /dev/null\n      docker volume prune -f \u003e /dev/null\n    path: /etc/cron.daily/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node update --availability drain $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker node demote $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker swarm leave\n    path: /root/bin/leave-swarm.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node rm $(docker node ls --format \"{{.ID}} {{.Status}} {{.Availability}}\" | grep \" Down Drain\" |  awk '{ print $1 }')\n    path: /root/bin/prune-nodes.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      for node_name in $*\n      do\n        docker node update --availability drain ${node_name}\n      done\n      sleep 10\n      docker node rm --force $*\n    path: /root/bin/rm-workers.sh\n    owner: root:root\n    permissions: \"0700\"\ngroups:\n  - docker\n",
                "content_type": "",
                "filename": "",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/cloud-config",
                "filename": "extra.cloud-config",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('0')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
                "content_type": "text/x-shellscript",
                "filename": "init_daemon.py",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('0')\ns3_bucket = 'voip.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
                "content_type": "text/x-shellscript",
                "filename": "init_node.py",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/x-shellscript",
                "filename": "extra.sh",
                "merge_type": ""
              }
            ],
            "rendered": "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"
          }
        },
        {
          "index_key": 1,
          "schema_version": 0,
          "attributes": {
            "base64_encode": true,
            "gzip": true,
            "id": "191882089",
            "part": [
              {
                "content": "#cloud-config\nbootcmd:\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-docker\", \"amazon-linux-extras\", \"install\", \"docker\" ]\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-epel\", \"amazon-linux-extras\", \"install\", \"epel\" ]\nrepo_update: true\nrepo_upgrade: all\npackages:\n  - docker\n  - python2-boto3\n  - yum-cron\noutput:\n  all: \"| tee -a /var/log/cloud-init-output.log\"\nmanage_resolve_conf: true\nresolve_conf:\n  name_servers: [ '169.254.169.253' ]\nruncmd:\n  - [ sysctl, -w, vm.max_map_count=262144 ]\n  - [ sysctl, -w, fs.file-max=65536 ]\n  - [ ulimit, -n, 65536 ]\n  - [ ulimit, -u, 4096 ]\nwrite_files:\n  - content: |\n      vm.max_map_count=262144\n      fs.file-max=65536\n    path: /etc/sysctl.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      *          soft    nproc     4096\n      *          soft    nofile    65536\n    path: /etc/security/limits.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      #!/bin/sh\n      docker image prune -f \u003e /dev/null\n      docker container prune -f \u003e /dev/null\n    path: /etc/cron.hourly/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker image prune --all -f \u003e /dev/null\n      docker network prune -f \u003e /dev/null\n      docker volume prune -f \u003e /dev/null\n    path: /etc/cron.daily/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node update --availability drain $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker node demote $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker swarm leave\n    path: /root/bin/leave-swarm.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node rm $(docker node ls --format \"{{.ID}} {{.Status}} {{.Availability}}\" | grep \" Down Drain\" |  awk '{ print $1 }')\n    path: /root/bin/prune-nodes.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      for node_name in $*\n      do\n        docker node update --availability drain ${node_name}\n      done\n      sleep 10\n      docker node rm --force $*\n    path: /root/bin/rm-workers.sh\n    owner: root:root\n    permissions: \"0700\"\ngroups:\n  - docker\n",
                "content_type": "",
                "filename": "",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/cloud-config",
                "filename": "extra.cloud-config",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('1')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
                "content_type": "text/x-shellscript",
                "filename": "init_daemon.py",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('1')\ns3_bucket = 'voip.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
                "content_type": "text/x-shellscript",
                "filename": "init_node.py",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/x-shellscript",
                "filename": "extra.sh",
                "merge_type": ""
              }
            ],
            "rendered": "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"
          }
        },
        {
          "index_key": 2,
          "schema_version": 0,
          "attributes": {
            "base64_encode": true,
            "gzip": true,
            "id": "3429169028",
            "part": [
              {
                "content": "#cloud-config\nbootcmd:\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-docker\", \"amazon-linux-extras\", \"install\", \"docker\" ]\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-epel\", \"amazon-linux-extras\", \"install\", \"epel\" ]\nrepo_update: true\nrepo_upgrade: all\npackages:\n  - docker\n  - python2-boto3\n  - yum-cron\noutput:\n  all: \"| tee -a /var/log/cloud-init-output.log\"\nmanage_resolve_conf: true\nresolve_conf:\n  name_servers: [ '169.254.169.253' ]\nruncmd:\n  - [ sysctl, -w, vm.max_map_count=262144 ]\n  - [ sysctl, -w, fs.file-max=65536 ]\n  - [ ulimit, -n, 65536 ]\n  - [ ulimit, -u, 4096 ]\nwrite_files:\n  - content: |\n      vm.max_map_count=262144\n      fs.file-max=65536\n    path: /etc/sysctl.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      *          soft    nproc     4096\n      *          soft    nofile    65536\n    path: /etc/security/limits.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      #!/bin/sh\n      docker image prune -f \u003e /dev/null\n      docker container prune -f \u003e /dev/null\n    path: /etc/cron.hourly/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker image prune --all -f \u003e /dev/null\n      docker network prune -f \u003e /dev/null\n      docker volume prune -f \u003e /dev/null\n    path: /etc/cron.daily/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node update --availability drain $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker node demote $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker swarm leave\n    path: /root/bin/leave-swarm.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node rm $(docker node ls --format \"{{.ID}} {{.Status}} {{.Availability}}\" | grep \" Down Drain\" |  awk '{ print $1 }')\n    path: /root/bin/prune-nodes.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      for node_name in $*\n      do\n        docker node update --availability drain ${node_name}\n      done\n      sleep 10\n      docker node rm --force $*\n    path: /root/bin/rm-workers.sh\n    owner: root:root\n    permissions: \"0700\"\ngroups:\n  - docker\n",
                "content_type": "",
                "filename": "",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/cloud-config",
                "filename": "extra.cloud-config",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('2')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
                "content_type": "text/x-shellscript",
                "filename": "init_daemon.py",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('2')\ns3_bucket = 'voip.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
                "content_type": "text/x-shellscript",
                "filename": "init_node.py",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/x-shellscript",
                "filename": "extra.sh",
                "merge_type": ""
              }
            ],
            "rendered": "H4sIAAAAAAAA/+Q6f2/bOJb/C+h3eKNuIHlgyU7SdrDe8wGdNjvX2056mM52cJcLBFp6djihSB1JOfF28t0PJCVZkmXHmU7vcDgHiCXy8fH9/kH6jeAauY5+3hQ4g7xkmhZE6klO7zH7CyxEyTMiN3P/x3c/Xnz/4e+Xb1//9O++Z96iTygVFXwGp/H0mffMi6I20DOvwS0JV0uU0QVPRUb5agbfLahuAdjNNd7rScEI5c+8H2mOO/ifp0yUWZQKvqQrbyGETvNs5gFEcAW+m6Sc6qhA6Y/BFzxF801y8g/BI0Z5eR/hvZZERZlIbx3UwKwZplxpwph5rGDh+vdthQWy4zaykHDtSSxEUhYZ0UYsssR6ZCVJhjMgjHkFSW/JCpXj35FoH4uNvhH8LFoILc7tyKbMo1QK7olSF6U2KwhjM/B/A40IEYHJmsgJE6tJizMHHDOx8r2ccLLCRKISbI2J0UBDWGvIA+Akx0ShXKNUM7iC4PTVn+Ozly9i930eGPZK3lKc2qhUszFEd2NY53FO7pOcFEkqSq7nZ6/OTl+8aCTfhl2qeEkZRjm5n796+fL8VQNVMppTPYaIj2HPTDmGF9M/m4k7STUmBlMlytQZ5Qx+88B+9hBVze6QYccLom9mMEGdThzNcTaZnlZWFxthWTBxx1HOQAqhZ+afW4syp8pYvpqBP33x4oU/TNi30HyUWGrzzQspUjti2DsAJwzR5mmYZkxLSfVmYuWlvgbxz7+ZLCifqJvq3WEHmpMVQiFLjhAt4Z9hkuF6wkvGunAGH6Ec5X7YFj/G+uMbUUq2mTgEkV0WV9sfw8p30+kXsBIRxg4yxFHfCXl7BOtrwcr8gIz6fGeE/k+yzUWG4IKXYXtNKCMLyqjeQCYJ5fCnsBYQXwrDQPD5c/zxjsg8vhQZvnv78BCMKpyKIRZwOh3YIsNcaPwDsCkDDAzJGtvyMwKxDNqZyEJ9fcHJfMuRHWAKomgpZE40+J8/x4YhMCxqokvlnl+3hPzw4MNvsJJYgA9vxR2Ht0bqZhDI3S0En6GQlGv40ynUkulzbI0kMturr8PxUjjuEpMuwNjEt40svDpWHW1PnxtUDw0Wjo9bkMydaFOs9+8LQuaRcUqUT5fDSoqy6Gbn/RXSW6oKoai21Q7RmqQ3OXL9FzBR2jA2923BELcrIP/3VVhtFHsKrS8i1BQPSUYwFzwuNr+TyPtI3SBjKpW00PvKwW8mpZJWT8jXVd3j0bwQUoNQnueISDRTMIe/EqbQKyRdE43JLW5gDoH9eClK3XojSXfAac8WNTRFN3710b1dexf3mH7UROp567EhzK3NIIo0U2uUdLlxzykxm8xtlHZAk5TEqdTV9M4kSh0XmLvpW9x0Zm9x4yb/Baax/ZudnX/3yryXnN7PJhPPcGJLTZ5iQnmG9zAHynUYnAWjWlS2vqnHp8HI8zJcgiuRhEwY5beh8ZFx7eIjY+B0Wb9eTa9hPgd/4s+ct6hYbXK7rIIYWx8zYQeZQgd1R/UNiAJ5hdu/80dAlLUEW5nNKudtBmJLUo1z5Hl0CS1tE55Bj9d/gjaLDiFdQsiFsZXYbBxTlVEZ+i3B+qNRvbdQcX67Mz+GqfhuOnVhtCsnf0BB/hhaFvjoqlrp/hjM4+Pw1oIMtLPhkfcon2qjNOZZ9V0hiitbj7OeAMgtZlSqY9f2tHvUqsnpNEJOFgyNodtq0x/DfpvYtYquv47+gGhmssX/RixbSpGD6eNSITHG+xQLQ6uCKshdijcSM+SaEqYupBSyDn+u+ateflXbuMjEakX5qhUmqydJeCby+k2VC9NJoGrmNc2xfi4lY3Rx5nkGG0qY12jjFer3dixMbEJOkpFXzy2Ioukbm3dChmtkc6Fi5GtqitQV6tB//+GH9xefLt6bXviX1z9dvrv8wR+NPO85fEQNa8JKVMAEyTCDxQb0DYLGvGBEo6e0kJj8KihPtLhFrhKiEk1WJvYvhGAunu2PgOo8WZTpLdrAvxa0iDVKSUzlFXjrInWlyhyCqpC29WBgaPuBiQVhkJL0BjOQqEqmlZekpZTIdVJvCXO4NGWJ9xwuTC5PNeSoSUY0aZFltalNcjJaiw2zYSXuuJTM+lFwo3Uxm0y6rfWLiZGD0pNsw0lO00mNNKqRGl8rjYEHo7YkMiuGHgFXQT30LguuPYkrKngtgwFoBxBcG/Ze//LRiEGUMkXlYXpmVaDFeVyPhgGmZ8EYWmjnrWejjYE16vzQEpuqjLtSwug/MHHxpapEVEJ4ltwIpQ1wWAU13/ft93tBMnDwVZpwOcTA2xONDvTWN+L0BtPbJCWMhVe+Q5Bqd2Zk0UQSjQb969HxK13w25471aHxSUiUKUO+EMeWkPoAySw/uL4WcE0F6qge8sdNwPbdcZI8yaIT5cMJhF23HEPtb6PrSq+pRJM01R0p+sp716jcKc0YhdIoUdkAYZZULfNhLbrzrvDKz2/NGkO/7avv19myltsS5u1UtlSaLOzRXpXrllUK2q4ELnhFRIZLYkIDTGH6n7xZkTKhMNyjl4Yog0Fws1dE/OsBazfh6LBoAPNCb6p210lKl5I7MbmYaTIsAV0WDOOjbH57jGrRuvNMqmt5VYp2ERnme/lrTGMQownqkUVh+f8v87/C7F+PYqUlLcLKMl279hU2dIjb+5nlToQQdhgdd6hodFWZuMlJjcH3FPZG8DVKrVzoA5u+tAACGU11tWUNW239WZPVVfA33ATXM7DPn0yeDK5tk63JyrTX9XaxwfjgCFqhTmTJOeWrJkepvgX9gNrZRwXZYFIGLYFP//bG2YxCHQ+SZ325yYGGps4A5ZaQdZGGo7hBHhvrGpnCtQ0cK000XgWXJDf8zecQVGQF8OB5KSNKwY9OE++qNY4dw2+S2FouCRWy5bhhZAyHdLetMs2qmBat7BfXpTwtEpJl0hRLHei+9Xfeu6A9s22/Om3ZwsYaaGIKajcVuoEaLy3G0Ca7VsW/CsqbYCjzzlxdnGW4KFehtXw4UXCi/DHsw34gIjzuV9ajGueqZN7fyQS4xkib4dqDjE1YL8L7lJUZJkaEc9vgV5w3hpSkgiuaoURT5ewx+bpJaqPbKn4PriVlGmXISL7ISMdMZ10L/8bt2y8Hw9F4EHWVFgb8ZAh6S2Ybuq57h2POvA062vK53MVxFfwkWO1rlR4CmzsGQCvPM9b2s1FrcL0P8hdr3i3ALRut0NHz5LAD02d5fHB2L4VHLdsht8o1FZ2uqt9rrep82E6bwGRWicWvmOrENHxmga19tkKpnbWJyISDWwG2Rfx4Pm6SuaHGmg/hG0DbEw6h0XLTFXqFbw7qPP5gn8OmJRqDK7EHlOSW2fZtdBV8L7JNcB1LJFm4BXeN66COnexgoFQYkIrfgamPF7qRc2hZG8TvFCbTxEb0oUW0mHZhTw/BnvqVTTyHv1Ke2WBbrWu80GTyUmGH235z+P80ePUT/W5mNRGorbTeFodXGNV1zW9A/m10zbnZDpyJaF1TNSNtC9tudEwc628wHpx1abIz1S0xrZs1B6pQJXaU8R2RxmJC/++2mzM2yERK9NY8O3vMT1QHs3lvib31eupe/YP107i9eNxeOupLyUUCG0bdZU99jNNk+6dUbI1dVI2jRdBs+TNZqflVR5yfdxKB/zfc+DPw+0nD380Zvi25/dmeCs98HsZHbtdLNod261SJnc2at2v7NPJaFlFVetWNmq31XLl3wJcOi3xIa+r8SfrqQCSHc1HQAQ4GOs0KQWw6PZOS5ouNRtVt0ka7gu18PmohyQrfmKZi7n+4vPiPD5cXybvXA2nnMXrbsMHe5X1qO1I6TOwjtOYbWjxGIy1OsgBOetcmO+v7RB6wmdH4EF3bpoaoumYKh+qncdewRtuGrn/6YY/4OsBhq4Y62KLbWrl/ltIs7eLclw8Pe4jBQ7jQNyh3WGwnf1u5aY15oU3alISvMDydwrd9zWw5O4B2SKDdavRnWXZ7gP3YHJXdPNrPMq8r0p+fZLAklGFmK1O5oXwFZKlRugv5OI79cc1ot7DUNMfYAoXuTiI2X5Tr8OX49OWoVVZ28p35LCSS2yZ3H8/JMZY0kGJ3aujhJn0fHbFJiXsnu8Gqs81x9ngc5gNwuxUG7Cnmn8O2urAnCM1ZwxiohpxsgJu6g5t6Y4GwJoxmMcAbm5yBAMc7ELw6c3ySVjpxxFE8GEZ6eeYJrjdtudqxLtbxqP+7nnQ0A5JQhXBRX1C2q01rD5UtcNFUnUtR8qxumob9ZtBfHrFSd9TaZJRECtbc9lSFZvdQZNh7RoMHH9sm3x5X1haVwhyeeEWXoyZRRjSZ5CQNRlXDHGeYiqy2HtuPZF+Cu/pJ4YRyjXJJUlRmOzU5UZN1kUbUJvycpMP7V+LC9Cz+VKShI2e0lcGu1JxAVu46dGe+tqadiZ2GaXjp0IWqIa7pq1q3kh0OdtH1TlTD+jRmyJf3uHjTlng7EdmobLCDaTITFxr23ldvxeGuvZclT41TQSEo1/Y+4OM5rN0PCPbnouYyW53H39vnbb03GoCMXYFXHb33wv3ALw2AKOgFjVa8ebnF8BShqvPhomtHpOq8EeYeb2/iyhPry4E8f0x68bxjr569tuF5nYvNP+IXgurmK/5MpU9fFD3z/jsAAP//GzUx7kIyAAA="
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "cloudinit_config",
      "name": "workers",
      "each": "list",
      "provider": "provider.cloudinit",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "base64_encode": true,
            "gzip": true,
            "id": "2913531068",
            "part": [
              {
                "content": "#cloud-config\nbootcmd:\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-docker\", \"amazon-linux-extras\", \"install\", \"docker\" ]\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-epel\", \"amazon-linux-extras\", \"install\", \"epel\" ]\nrepo_update: true\nrepo_upgrade: all\npackages:\n  - docker\n  - python2-boto3\n  - yum-cron\noutput:\n  all: \"| tee -a /var/log/cloud-init-output.log\"\nmanage_resolve_conf: true\nresolve_conf:\n  name_servers: [ '169.254.169.253' ]\nruncmd:\n  - [ sysctl, -w, vm.max_map_count=262144 ]\n  - [ sysctl, -w, fs.file-max=65536 ]\n  - [ ulimit, -n, 65536 ]\n  - [ ulimit, -u, 4096 ]\nwrite_files:\n  - content: |\n      vm.max_map_count=262144\n      fs.file-max=65536\n    path: /etc/sysctl.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      *          soft    nproc     4096\n      *          soft    nofile    65536\n    path: /etc/security/limits.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      #!/bin/sh\n      docker image prune -f \u003e /dev/null\n      docker container prune -f \u003e /dev/null\n    path: /etc/cron.hourly/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker image prune --all -f \u003e /dev/null\n      docker network prune -f \u003e /dev/null\n      docker volume prune -f \u003e /dev/null\n    path: /etc/cron.daily/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node update --availability drain $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker node demote $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker swarm leave\n    path: /root/bin/leave-swarm.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node rm $(docker node ls --format \"{{.ID}} {{.Status}} {{.Availability}}\" | grep \" Down Drain\" |  awk '{ print $1 }')\n    path: /root/bin/prune-nodes.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      for node_name in $*\n      do\n        docker node update --availability drain ${node_name}\n      done\n      sleep 10\n      docker node rm --force $*\n    path: /root/bin/rm-workers.sh\n    owner: root:root\n    permissions: \"0700\"\ngroups:\n  - docker\n",
                "content_type": "",
                "filename": "",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/cloud-config",
                "filename": "extra.cloud-config",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('0')\ns3_bucket = 'voip.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
                "content_type": "text/x-shellscript",
                "filename": "init_worker.py",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/x-shellscript",
                "filename": "extra.sh",
                "merge_type": ""
              }
            ],
            "rendered": "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"
          }
        },
        {
          "index_key": 1,
          "schema_version": 0,
          "attributes": {
            "base64_encode": true,
            "gzip": true,
            "id": "3672652325",
            "part": [
              {
                "content": "#cloud-config\nbootcmd:\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-docker\", \"amazon-linux-extras\", \"install\", \"docker\" ]\n  - [ \"cloud-init-per\", \"once\", \"amazon-linux-extras-epel\", \"amazon-linux-extras\", \"install\", \"epel\" ]\nrepo_update: true\nrepo_upgrade: all\npackages:\n  - docker\n  - python2-boto3\n  - yum-cron\noutput:\n  all: \"| tee -a /var/log/cloud-init-output.log\"\nmanage_resolve_conf: true\nresolve_conf:\n  name_servers: [ '169.254.169.253' ]\nruncmd:\n  - [ sysctl, -w, vm.max_map_count=262144 ]\n  - [ sysctl, -w, fs.file-max=65536 ]\n  - [ ulimit, -n, 65536 ]\n  - [ ulimit, -u, 4096 ]\nwrite_files:\n  - content: |\n      vm.max_map_count=262144\n      fs.file-max=65536\n    path: /etc/sysctl.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      *          soft    nproc     4096\n      *          soft    nofile    65536\n    path: /etc/security/limits.d/01-docker.conf\n    owner: root:root\n    permissions: \"0444\"\n  - content: |\n      #!/bin/sh\n      docker image prune -f \u003e /dev/null\n      docker container prune -f \u003e /dev/null\n    path: /etc/cron.hourly/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker image prune --all -f \u003e /dev/null\n      docker network prune -f \u003e /dev/null\n      docker volume prune -f \u003e /dev/null\n    path: /etc/cron.daily/docker-prune.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node update --availability drain $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker node demote $(docker info -f '{{.Swarm.NodeID}}')\n      sleep 10\n      docker swarm leave\n    path: /root/bin/leave-swarm.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      docker node rm $(docker node ls --format \"{{.ID}} {{.Status}} {{.Availability}}\" | grep \" Down Drain\" |  awk '{ print $1 }')\n    path: /root/bin/prune-nodes.sh\n    owner: root:root\n    permissions: \"0700\"\n  - content: |\n      #!/bin/sh\n      for node_name in $*\n      do\n        docker node update --availability drain ${node_name}\n      done\n      sleep 10\n      docker node rm --force $*\n    path: /root/bin/rm-workers.sh\n    owner: root:root\n    permissions: \"0700\"\ngroups:\n  - docker\n",
                "content_type": "",
                "filename": "",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/cloud-config",
                "filename": "extra.cloud-config",
                "merge_type": ""
              },
              {
                "content": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('1')\ns3_bucket = 'voip.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
                "content_type": "text/x-shellscript",
                "filename": "init_worker.py",
                "merge_type": ""
              },
              {
                "content": "",
                "content_type": "text/x-shellscript",
                "filename": "extra.sh",
                "merge_type": ""
              }
            ],
            "rendered": "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"
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "template_file",
      "name": "init_daemon",
      "each": "list",
      "provider": "provider.template",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "a12c44acb7f5e373ffb894facfcb76514b7dcf7027ff962dc00387fbab427fe0",
            "rendered": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('0')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "template": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = ${daemon_tls}\nprivate_key = '''${private_key}'''\ncert = '''${cert}'''\nca_cert = '''${ca_cert}'''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('${instance_index}')\ndaemon_count = int('${daemon_count}')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "vars": {
              "ca_cert": "",
              "cert": "",
              "daemon_count": "0",
              "daemon_tls": "False",
              "instance_index": "0",
              "private_key": ""
            }
          }
        },
        {
          "index_key": 1,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "8c1da05dcfc23b623f97304e46c09080560a6a7e64b03c0118276f23c59ab80d",
            "rendered": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('1')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "template": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = ${daemon_tls}\nprivate_key = '''${private_key}'''\ncert = '''${cert}'''\nca_cert = '''${ca_cert}'''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('${instance_index}')\ndaemon_count = int('${daemon_count}')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "vars": {
              "ca_cert": "",
              "cert": "",
              "daemon_count": "0",
              "daemon_tls": "False",
              "instance_index": "1",
              "private_key": ""
            }
          }
        },
        {
          "index_key": 2,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "33017bb2edad4aeb70e6c77afd6cb4c4f052c84cca8a6970b2d1fab6baae7702",
            "rendered": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = False\nprivate_key = ''''''\ncert = ''''''\nca_cert = ''''''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('2')\ndaemon_count = int('0')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "template": "#!/usr/bin/env python\nimport os\n\ndaemon_tls = ${daemon_tls}\nprivate_key = '''${private_key}'''\ncert = '''${cert}'''\nca_cert = '''${ca_cert}'''\ndocker_service = '''[Service]\nExecStart=\nExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/etc/docker/ca.crt --tlscert=/etc/docker/cert.pem --tlskey=/etc/docker/key.pem -H 0.0.0.0:2376 -H unix://\n'''\ninstance_index = int('${instance_index}')\ndaemon_count = int('${daemon_count}')\n\ndef write_or_link(path, content):\n  if content[0] == \"/\":\n    os.symlink(content, path)\n  else:\n    with open(path, \"w\") as text_file:\n      text_file.write(content)\n\nif daemon_tls and instance_index \u003c daemon_count:\n    if (not os.path.isdir(\"/etc/docker\")):\n      os.mkdir(\"/etc/docker\", 0o700)\n    write_or_link(\"/etc/docker/key.pem\", private_key)\n    write_or_link(\"/etc/docker/cert.pem\", cert)\n    write_or_link(\"/etc/docker/ca.crt\", ca_cert)\n\n    if (not os.path.isdir(\"/etc/systemd/system/docker.service.d\")):\n      os.makedirs(\"/etc/systemd/system/docker.service.d\")\n    with open(\"/etc/systemd/system/docker.service.d/10-enable-tls.conf\",  \"w\") as text_file:\n        text_file.write(docker_service)\n",
            "vars": {
              "ca_cert": "",
              "cert": "",
              "daemon_count": "0",
              "daemon_tls": "False",
              "instance_index": "2",
              "private_key": ""
            }
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "template_file",
      "name": "init_manager",
      "each": "list",
      "provider": "provider.template",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "2517c9fa8f4c9c999c6398f011bbc5b6ec7bdd4bedb4db9b89fa48ab80472e33",
            "rendered": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('0')\ns3_bucket = 'docker-swarm.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "template": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('${store_join_tokens_as_tags}')\ninstance_index = int('${instance_index}')\ns3_bucket = '${s3_bucket}'\nvpc_name = '${vpc_name}'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "vars": {
              "instance_index": "0",
              "region_name": "us-east-1",
              "s3_bucket": "docker-swarm.terraform",
              "store_join_tokens_as_tags": "0",
              "vpc_name": "docker-swarm"
            }
          }
        },
        {
          "index_key": 1,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "a55a7e009250989c0419f22e80fd64ac6e7aa632d418c1462b5a45ebe687f9f1",
            "rendered": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('1')\ns3_bucket = 'docker-swarm.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "template": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('${store_join_tokens_as_tags}')\ninstance_index = int('${instance_index}')\ns3_bucket = '${s3_bucket}'\nvpc_name = '${vpc_name}'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "vars": {
              "instance_index": "1",
              "region_name": "us-east-1",
              "s3_bucket": "docker-swarm.terraform",
              "store_join_tokens_as_tags": "0",
              "vpc_name": "docker-swarm"
            }
          }
        },
        {
          "index_key": 2,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "bcc899f0f92a5c7f099f685f3512508f61e458561b6625839dfbc614561cd280",
            "rendered": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('2')\ns3_bucket = 'docker-swarm.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "template": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('${store_join_tokens_as_tags}')\ninstance_index = int('${instance_index}')\ns3_bucket = '${s3_bucket}'\nvpc_name = '${vpc_name}'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "vars": {
              "instance_index": "2",
              "region_name": "us-east-1",
              "s3_bucket": "docker-swarm.terraform",
              "store_join_tokens_as_tags": "0",
              "vpc_name": "docker-swarm"
            }
          }
        }
      ]
    },
    {
      "mode": "data",
      "type": "template_file",
      "name": "init_worker",
      "each": "list",
      "provider": "provider.template",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "2517c9fa8f4c9c999c6398f011bbc5b6ec7bdd4bedb4db9b89fa48ab80472e33",
            "rendered": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('0')\ns3_bucket = 'docker-swarm.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "template": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('${store_join_tokens_as_tags}')\ninstance_index = int('${instance_index}')\ns3_bucket = '${s3_bucket}'\nvpc_name = '${vpc_name}'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "vars": {
              "instance_index": "0",
              "region_name": "us-east-1",
              "s3_bucket": "docker-swarm.terraform",
              "store_join_tokens_as_tags": "0",
              "vpc_name": "docker-swarm"
            }
          }
        },
        {
          "index_key": 1,
          "schema_version": 0,
          "attributes": {
            "filename": null,
            "id": "a55a7e009250989c0419f22e80fd64ac6e7aa632d418c1462b5a45ebe687f9f1",
            "rendered": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('0')\ninstance_index = int('1')\ns3_bucket = 'docker-swarm.terraform'\nvpc_name = 'docker-swarm'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "template": "#!/usr/bin/env python\nfrom botocore.exceptions import NoCredentialsError\nimport boto3\nimport json\nimport logging\nimport os\nimport random\nimport subprocess\nimport time\nimport urllib2\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"WARNING\"))\n\n# Set values loaded by the template\nstore_join_tokens_as_tags = bool('${store_join_tokens_as_tags}')\ninstance_index = int('${instance_index}')\ns3_bucket = '${s3_bucket}'\nvpc_name = '${vpc_name}'\n\n# Global cached results\n_current_instance = None\n\n# Extract metadata\ninstance_identity = json.load(urllib2.urlopen('http://169.254.169.254/latest/dynamic/instance-identity/document'))\ninstance_id = instance_identity['instanceId']\nregion_name = instance_identity['region']\n\n# AWS resources\nec2 = boto3.resource('ec2', region_name=region_name)\ns3 = boto3.resource('s3', region_name=region_name)\n\ndef initialize_system_daemons_and_hostname():\n    \"\"\"\n    Load system daemons and host name\n    \"\"\"\n    subprocess.check_call([\"systemctl\", \"daemon-reload\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"start\", \"docker.service\"])\n    subprocess.check_call([\"systemctl\", \"enable\", \"yum-cron\"])\n\n    subprocess.check_call([\"hostnamectl\", \"set-hostname\",\n        \"manager%d-%s\" % (instance_index, vpc_name)])\n\ndef create_swap():\n    \"\"\"\n    Initializes and registeres the swap volume\n    \"\"\"\n    subprocess.check_output([\"mkswap\", \"/dev/xvdf\"])\n    f = open(\"/etc/fstab\", \"a\")\n    f.write(\"/dev/xvdf none swap defaults 0 0\\n\")\n    f.close()\n    subprocess.check_output([\"swapon\", \"-a\"])\n\ndef initialize_swarm():\n    \"\"\"\n    Initializes an empty swarm and returns the tokens as a tuple.\n    \"\"\"\n    subprocess.check_call([\"docker\", \"swarm\", \"init\"])\n    manager_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"manager\"]).strip()\n\n    worker_token = subprocess.check_output(\n        [\"docker\", \"swarm\", \"join-token\", \"-q\", \"worker\"]).strip()\n    return (manager_token, worker_token)\n\ndef instance_tags(instance):\n    \"\"\"\n    Converts boto3 tags to a dict()\n    \"\"\"\n    return {tag['Key']: tag['Value'] for tag in instance.tags}\n\ndef get_running_instances():\n    \"\"\"\n    Gets the running instances in a VPC as a set.\n    \"\"\"\n    return { vpc_instance for vpc_instance in get_vpc().instances.all() if vpc_instance.state['Name'] == 'running' }\n\nclass ManagerInstance:\n    def __init__(self, instance, manager_token, worker_token):\n        self.ip = instance.private_ip_address\n        self.manager_token = manager_token\n        self.worker_token = worker_token\n\ndef join_swarm_with_token(swarm_manager_ip, token):\n    \"\"\"\n    Joins the swarm\n    \"\"\"\n    logging.debug(\"join %s %s\", swarm_manager_ip, token)\n    subprocess.check_call(\n        [\"docker\", \"swarm\", \"join\", \"--token\", token, swarm_manager_ip])\n\n\ndef get_manager_instance_vpc_tags(exclude_self=False):\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        vpc_instance_tags = instance_tags(instance=vpc_instance)\n        if vpc_instance_tags['Role'] == 'manager' and vpc_instance_tags['ManagerJoinToken'] and vpc_instance_tags['WorkerJoinToken']:\n            return ManagerInstance(\n                vpc_instance,\n                vpc_instance_tags['ManagerJoinToken'],\n                vpc_instance_tags['WorkerJoinToken'])\n\n    return None\n\ndef get_manager_instance_s3(exclude_self=False):\n\n    def get_object_from_s3(name):\n        \"\"\"\n        Gets an object from S3, returns None for any error\n        \"\"\"\n        try:\n            object = s3.Object(s3_bucket, name)\n            return object.get()['Body'].read()\n        except:\n            return None\n\n    manager_token = get_object_from_s3(\"manager_token\")\n    worker_token = get_object_from_s3(\"worker_token\")\n    manager0_ip = get_object_from_s3(\"ip0\")\n    manager1_ip = get_object_from_s3(\"ip1\")\n\n    # Find the manager instance to use\n    manager_instance = None\n    instances_considered = get_running_instances()\n    if exclude_self:\n        instances_considered = filter(lambda vpc_instance: vpc_instance != get_current_instance(), instances_considered)\n    for vpc_instance in instances_considered:\n        if vpc_instance.private_ip_address == manager0_ip or vpc_instance.private_ip_address == manager1_ip:\n            manager_instance = vpc_instance\n\n    if manager_instance and manager_token and worker_token:\n        return ManagerInstance(\n            manager_instance,\n            manager_token,\n            worker_token)\n    else:\n        logger.warning(\"Unable to locate manager manager_token=%s worker_token=%s manager0_ip=%s manager1_ip=%s\", manager_token, worker_token, manager0_ip, manager1_ip)\n        return None\n\n\ndef update_tokens_vpc_tags(instance, manager_token, worker_token):\n    instance.create_tags(\n        Tags=[\n            {\n                \"Key\": \"ManagerJoinToken\",\n                \"Value\": manager_token\n            },\n            {\n                \"Key\": \"WorkerJoinToken\",\n                \"Value\": worker_token\n            }\n        ]\n    )\n    logger.debug(\"update %s %s %s\", instance.private_ip_address, manager_token, worker_token)\n\ndef update_tokens_s3(instance, manager_token, worker_token):\n    manager_token_object = s3.Object(s3_bucket, 'manager_token')\n    manager_token_object.put(Body=bytes(manager_token),\n                             StorageClass=\"ONEZONE_IA\")\n    worker_token_object = s3.Object(s3_bucket, 'worker_token')\n    worker_token_object.put(Body=bytes(worker_token),\n                            StorageClass=\"ONEZONE_IA\")\n    myip_object = s3.Object(s3_bucket, 'ip%d' % instance_index)\n    myip_object.put(Body=bytes(instance.private_ip_address), StorageClass=\"ONEZONE_IA\")\n\ndef join_as_manager(get_manager_instance, update_tokens):\n    def initialize_swarm_and_update_tokens():\n        (manager_token, worker_token) = initialize_swarm()\n        update_tokens(get_current_instance(), manager_token, worker_token)\n\n    another_manager_instance = None\n    for attempt in range(10 * instance_index):\n        another_manager_instance = get_manager_instance(exclude_self=True)\n        if another_manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n\n    if another_manager_instance == None:\n        initialize_swarm_and_update_tokens()\n    else:\n        try:\n            join_swarm_with_token(another_manager_instance.ip, another_manager_instance.manager_token)\n            update_tokens(get_current_instance(), another_manager_instance.manager_token, another_manager_instance.worker_token)\n        except:\n            # Unable to join the swarm, it may no longer be valid.  Create a new one.\n            initialize_swarm_and_update_tokens()\n\ndef join_as_worker(get_manager_instance):\n    manager_instance = None\n    for attempt in range(100):\n        manager_instance = get_manager_instance()\n        if manager_instance == None:\n            logger.warning(\"Attempt #%d failed, retrying after sleep...\", attempt)\n            time.sleep(random.randint(5,15))\n        else:\n            break\n    if manager_instance == None:\n        raise Exception(\"Unable to join swarm, no manager found\")\n\n    join_swarm_with_token(manager_instance.ip, manager_instance.worker_token)\n\ndef is_manager_role():\n    return instance_tags(get_current_instance())['Role'] == 'manager'\n\ndef get_vpc():\n    mac = urllib2.urlopen('http://169.254.169.254/latest/meta-data/mac').read().decode()\n    vpc_id = urllib2.urlopen('http://169.254.169.254/latest/meta-data/network/interfaces/macs/%s/vpc-id' % mac).read().decode()\n    return ec2.Vpc(vpc_id)\n\ndef get_current_instance():\n    global _current_instance\n    if _current_instance:\n        return _current_instance\n    _current_instance = ec2.Instance(instance_id)\n    return _current_instance\n\ndef join_swarm():\n\n    get_manager_instance = get_manager_instance_vpc_tags\n    update_tokens = update_tokens_vpc_tags\n\n    if not store_join_tokens_as_tags:\n        # Set function points to S3 version\n        try:\n            bucket = s3.Bucket(s3_bucket)\n            bucket.objects.all()\n        except NoCredentialsError as e:\n            time.sleep(5)\n        get_manager_instance = get_manager_instance_s3\n        update_tokens = update_tokens_s3\n\n    if is_manager_role():\n        join_as_manager(get_manager_instance, update_tokens)\n    else:\n        join_as_worker(get_manager_instance)\n\ninitialize_system_daemons_and_hostname()\njoin_swarm()\ncreate_swap()\n",
            "vars": {
              "instance_index": "1",
              "region_name": "us-east-1",
              "s3_bucket": "docker-swarm.terraform",
              "store_join_tokens_as_tags": "0",
              "vpc_name": "docker-swarm"
            }
          }
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_cloudwatch_metric_alarm",
      "name": "high-cpu-managers",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_cloudwatch_metric_alarm",
      "name": "high-cpu-workers",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_cloudwatch_metric_alarm",
      "name": "low-cpu-credit-managers",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_cloudwatch_metric_alarm",
      "name": "low-cpu-credit-workers",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_iam_instance_profile",
      "name": "ec2",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "arn": "arn:aws:iam::569484333419:instance-profile/docker-swarm-ec2",
            "create_date": "2020-06-04T16:07:34Z",
            "id": "docker-swarm-ec2",
            "name": "docker-swarm-ec2",
            "name_prefix": null,
            "path": "/",
            "role": "docker-swarm-ec2",
            "roles": [],
            "unique_id": "AIPAYJF7JKFV3T2CXOP2N"
          },
          "private": "bnVsbA==",
          "dependencies": [
            "aws_iam_role.ec2"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_iam_policy",
      "name": "s3-access-role-policy",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "arn": "arn:aws:iam::569484333419:policy/docker-swarm-ec2-policy",
            "description": "",
            "id": "arn:aws:iam::569484333419:policy/docker-swarm-ec2-policy",
            "name": "docker-swarm-ec2-policy",
            "name_prefix": null,
            "path": "/",
            "policy": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:PutObject\",\n        \"s3:ListBucket\",\n        \"s3:GetObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::docker-swarm.terraform/*\",\n        \"arn:aws:s3:::docker-swarm.terraform\"\n      ]\n    },\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"ec2:DescribeVpcs\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:DescribeInstances\",\n        \"ec2:DeleteTags\",\n        \"ec2:CreateTags\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}"
          },
          "private": "bnVsbA==",
          "dependencies": [
            "aws_s3_bucket.terraform"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_iam_role",
      "name": "ec2",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "arn": "arn:aws:iam::569484333419:role/docker-swarm-ec2",
            "assume_role_policy": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Sid\":\"\",\"Effect\":\"Allow\",\"Principal\":{\"Service\":\"ec2.amazonaws.com\"},\"Action\":\"sts:AssumeRole\"}]}",
            "create_date": "2020-06-04T16:07:33Z",
            "description": "Allows reading of infrastructure secrets",
            "force_detach_policies": false,
            "id": "docker-swarm-ec2",
            "max_session_duration": 3600,
            "name": "docker-swarm-ec2",
            "name_prefix": null,
            "path": "/",
            "permissions_boundary": null,
            "tags": null,
            "unique_id": "AROAYJF7JKFV7YQWEK24F"
          },
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_iam_role_policy_attachment",
      "name": "s3-access-role-policy",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "docker-swarm-ec2-20200604160752401000000002",
            "policy_arn": "arn:aws:iam::569484333419:policy/docker-swarm-ec2-policy",
            "role": "docker-swarm-ec2"
          },
          "private": "bnVsbA==",
          "dependencies": [
            "aws_iam_policy.s3-access-role-policy",
            "aws_iam_role.ec2",
            "aws_s3_bucket.terraform"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "managers",
      "each": "list",
      "provider": "provider.aws",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "ami": "ami-0f84e2a3635d2fac9",
            "arn": "arn:aws:ec2:us-east-1:569484333419:instance/i-0fa1343dee5834fff",
            "associate_public_ip_address": true,
            "availability_zone": "us-east-1a",
            "cpu_core_count": 1,
            "cpu_threads_per_core": 2,
            "credit_specification": [
              {
                "cpu_credits": "standard"
              }
            ],
            "disable_api_termination": false,
            "ebs_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "xvdf",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "snapshot_id": "",
                "volume_id": "vol-0a9074f05a1543d54",
                "volume_size": 1,
                "volume_type": "gp2"
              }
            ],
            "ebs_optimized": false,
            "ephemeral_block_device": [],
            "get_password_data": false,
            "hibernation": false,
            "host_id": null,
            "iam_instance_profile": "docker-swarm-ec2",
            "id": "i-0fa1343dee5834fff",
            "instance_initiated_shutdown_behavior": null,
            "instance_state": "running",
            "instance_type": "t3.micro",
            "ipv6_address_count": 0,
            "ipv6_addresses": [],
            "key_name": "",
            "metadata_options": [
              {
                "http_endpoint": "enabled",
                "http_put_response_hop_limit": 1,
                "http_tokens": "optional"
              }
            ],
            "monitoring": false,
            "network_interface": [],
            "network_interface_id": null,
            "outpost_arn": "",
            "password_data": "",
            "placement_group": "",
            "primary_network_interface_id": "eni-0698621ef4f9beac3",
            "private_dns": "ip-10-100-10-10.ec2.internal",
            "private_ip": "10.100.10.10",
            "public_dns": "ec2-54-224-82-117.compute-1.amazonaws.com",
            "public_ip": "54.224.82.117",
            "root_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "/dev/xvda",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "volume_id": "vol-0ba559667c678da6a",
                "volume_size": 8,
                "volume_type": "gp2"
              }
            ],
            "security_groups": [],
            "source_dest_check": true,
            "subnet_id": "subnet-009f7db49a1b27527",
            "tags": {
              "ManagerJoinToken": "",
              "Name": "docker-swarm manager 0",
              "Role": "manager",
              "WorkerJoinToken": ""
            },
            "tenancy": "default",
            "timeouts": null,
            "user_data": null,
            "user_data_base64": "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",
            "volume_tags": {},
            "vpc_security_group_ids": [
              "sg-07a0698db9d4b5637",
              "sg-0fea47628064af96a"
            ]
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMCwidXBkYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "aws_iam_instance_profile.ec2",
            "aws_iam_role.ec2",
            "aws_s3_bucket.terraform",
            "aws_security_group.daemon",
            "aws_security_group.daemon_ssh",
            "aws_security_group.docker",
            "aws_subnet.managers"
          ]
        },
        {
          "index_key": 1,
          "schema_version": 1,
          "attributes": {
            "ami": "ami-0f84e2a3635d2fac9",
            "arn": "arn:aws:ec2:us-east-1:569484333419:instance/i-005b0b45a51b649d4",
            "associate_public_ip_address": true,
            "availability_zone": "us-east-1b",
            "cpu_core_count": 1,
            "cpu_threads_per_core": 2,
            "credit_specification": [
              {
                "cpu_credits": "standard"
              }
            ],
            "disable_api_termination": false,
            "ebs_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "xvdf",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "snapshot_id": "",
                "volume_id": "vol-074a9504249c658e9",
                "volume_size": 1,
                "volume_type": "gp2"
              }
            ],
            "ebs_optimized": false,
            "ephemeral_block_device": [],
            "get_password_data": false,
            "hibernation": false,
            "host_id": null,
            "iam_instance_profile": "docker-swarm-ec2",
            "id": "i-005b0b45a51b649d4",
            "instance_initiated_shutdown_behavior": null,
            "instance_state": "running",
            "instance_type": "t3.micro",
            "ipv6_address_count": 0,
            "ipv6_addresses": [],
            "key_name": "",
            "metadata_options": [
              {
                "http_endpoint": "enabled",
                "http_put_response_hop_limit": 1,
                "http_tokens": "optional"
              }
            ],
            "monitoring": false,
            "network_interface": [],
            "network_interface_id": null,
            "outpost_arn": "",
            "password_data": "",
            "placement_group": "",
            "primary_network_interface_id": "eni-0019e589a60849844",
            "private_dns": "ip-10-100-11-11.ec2.internal",
            "private_ip": "10.100.11.11",
            "public_dns": "ec2-3-233-238-35.compute-1.amazonaws.com",
            "public_ip": "3.233.238.35",
            "root_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "/dev/xvda",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "volume_id": "vol-032c0e9aabdc88143",
                "volume_size": 8,
                "volume_type": "gp2"
              }
            ],
            "security_groups": [],
            "source_dest_check": true,
            "subnet_id": "subnet-048f7c9eda782262a",
            "tags": {
              "ManagerJoinToken": "",
              "Name": "docker-swarm manager 1",
              "Role": "manager",
              "WorkerJoinToken": ""
            },
            "tenancy": "default",
            "timeouts": null,
            "user_data": null,
            "user_data_base64": "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",
            "volume_tags": {},
            "vpc_security_group_ids": [
              "sg-07a0698db9d4b5637",
              "sg-0fea47628064af96a"
            ]
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMCwidXBkYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "aws_iam_instance_profile.ec2",
            "aws_iam_role.ec2",
            "aws_s3_bucket.terraform",
            "aws_security_group.daemon",
            "aws_security_group.daemon_ssh",
            "aws_security_group.docker",
            "aws_subnet.managers"
          ]
        },
        {
          "index_key": 2,
          "schema_version": 1,
          "attributes": {
            "ami": "ami-0f84e2a3635d2fac9",
            "arn": "arn:aws:ec2:us-east-1:569484333419:instance/i-0e3603c56a73b1446",
            "associate_public_ip_address": true,
            "availability_zone": "us-east-1c",
            "cpu_core_count": 1,
            "cpu_threads_per_core": 2,
            "credit_specification": [
              {
                "cpu_credits": "standard"
              }
            ],
            "disable_api_termination": false,
            "ebs_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "xvdf",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "snapshot_id": "",
                "volume_id": "vol-07e65abc2b0d981ed",
                "volume_size": 1,
                "volume_type": "gp2"
              }
            ],
            "ebs_optimized": false,
            "ephemeral_block_device": [],
            "get_password_data": false,
            "hibernation": false,
            "host_id": null,
            "iam_instance_profile": "docker-swarm-ec2",
            "id": "i-0e3603c56a73b1446",
            "instance_initiated_shutdown_behavior": null,
            "instance_state": "running",
            "instance_type": "t3.micro",
            "ipv6_address_count": 0,
            "ipv6_addresses": [],
            "key_name": "",
            "metadata_options": [
              {
                "http_endpoint": "enabled",
                "http_put_response_hop_limit": 1,
                "http_tokens": "optional"
              }
            ],
            "monitoring": false,
            "network_interface": [],
            "network_interface_id": null,
            "outpost_arn": "",
            "password_data": "",
            "placement_group": "",
            "primary_network_interface_id": "eni-0de9c19e435e72602",
            "private_dns": "ip-10-100-12-12.ec2.internal",
            "private_ip": "10.100.12.12",
            "public_dns": "ec2-54-84-238-85.compute-1.amazonaws.com",
            "public_ip": "54.84.238.85",
            "root_block_device": [
              {
                "delete_on_termination": true,
                "device_name": "/dev/xvda",
                "encrypted": false,
                "iops": 100,
                "kms_key_id": "",
                "volume_id": "vol-059be875aa63958ee",
                "volume_size": 8,
                "volume_type": "gp2"
              }
            ],
            "security_groups": [],
            "source_dest_check": true,
            "subnet_id": "subnet-0e5abf73a4eada2bc",
            "tags": {
              "ManagerJoinToken": "",
              "Name": "docker-swarm manager 2",
              "Role": "manager",
              "WorkerJoinToken": ""
            },
            "tenancy": "default",
            "timeouts": null,
            "user_data": null,
            "user_data_base64": "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",
            "volume_tags": {},
            "vpc_security_group_ids": [
              "sg-07a0698db9d4b5637",
              "sg-0fea47628064af96a"
            ]
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMCwidXBkYXRlIjo2MDAwMDAwMDAwMDB9LCJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "aws_iam_instance_profile.ec2",
            "aws_iam_role.ec2",
            "aws_s3_bucket.terraform",
            "aws_security_group.daemon",
            "aws_security_group.daemon_ssh",
            "aws_security_group.docker",
            "aws_subnet.managers"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_instance",
      "name": "workers",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_s3_bucket",
      "name": "terraform",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "acceleration_status": "",
            "acl": "private",
            "arn": "arn:aws:s3:::docker-swarm.terraform",
            "bucket": "docker-swarm.terraform",
            "bucket_domain_name": "docker-swarm.terraform.s3.amazonaws.com",
            "bucket_prefix": null,
            "bucket_regional_domain_name": "docker-swarm.terraform.s3.amazonaws.com",
            "cors_rule": [],
            "force_destroy": true,
            "grant": [],
            "hosted_zone_id": "Z3AQBSTGFYJSTF",
            "id": "docker-swarm.terraform",
            "lifecycle_rule": [
              {
                "abort_incomplete_multipart_upload_days": 0,
                "enabled": true,
                "expiration": [],
                "id": "tf-s3-lifecycle-20200604160734591900000001",
                "noncurrent_version_expiration": [],
                "noncurrent_version_transition": [],
                "prefix": "",
                "tags": null,
                "transition": [
                  {
                    "date": "",
                    "days": 30,
                    "storage_class": "ONEZONE_IA"
                  }
                ]
              }
            ],
            "logging": [],
            "object_lock_configuration": [],
            "policy": null,
            "region": "us-east-1",
            "replication_configuration": [],
            "request_payer": "BucketOwner",
            "server_side_encryption_configuration": [],
            "tags": {
              "Name": "docker-swarm Swarm"
            },
            "versioning": [
              {
                "enabled": false,
                "mfa_delete": false
              }
            ],
            "website": [],
            "website_domain": null,
            "website_endpoint": null
          },
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_s3_bucket_public_access_block",
      "name": "terraform",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "block_public_acls": true,
            "block_public_policy": true,
            "bucket": "docker-swarm.terraform",
            "id": "docker-swarm.terraform",
            "ignore_public_acls": true,
            "restrict_public_buckets": true
          },
          "private": "bnVsbA==",
          "dependencies": [
            "aws_s3_bucket.terraform"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_security_group",
      "name": "daemon",
      "each": "list",
      "provider": "provider.aws",
      "instances": []
    },
    {
      "mode": "managed",
      "type": "aws_security_group",
      "name": "daemon_ssh",
      "each": "list",
      "provider": "provider.aws",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:security-group/sg-04170b5c72cfdb989",
            "description": "Docker Daemon SSH port",
            "egress": [],
            "id": "sg-04170b5c72cfdb989",
            "ingress": [
              {
                "cidr_blocks": [
                  "0.0.0.0/0"
                ],
                "description": "",
                "from_port": 22,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "tcp",
                "security_groups": [],
                "self": false,
                "to_port": 22
              }
            ],
            "name": "docker-daemon-ssh",
            "name_prefix": null,
            "owner_id": "569484333419",
            "revoke_rules_on_delete": false,
            "tags": {
              "Name": "docker-swarm Docker Daemon SSH"
            },
            "timeouts": {
              "create": "2m",
              "delete": "2m"
            },
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwfSwic2NoZW1hX3ZlcnNpb24iOiIxIn0="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_security_group",
      "name": "docker",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:security-group/sg-0fea47628064af96a",
            "description": "Docker Swarm ports",
            "egress": [
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker swarm (tcp)",
                "from_port": 0,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "tcp",
                "security_groups": [],
                "self": false,
                "to_port": 0
              },
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker swarm (udp)",
                "from_port": 0,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "udp",
                "security_groups": [],
                "self": false,
                "to_port": 0
              }
            ],
            "id": "sg-0fea47628064af96a",
            "ingress": [
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker container network discovery",
                "from_port": 7946,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "tcp",
                "security_groups": [],
                "self": false,
                "to_port": 7946
              },
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker container network discovery",
                "from_port": 7946,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "udp",
                "security_groups": [],
                "self": false,
                "to_port": 7946
              },
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker overlay network",
                "from_port": 4789,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "udp",
                "security_groups": [],
                "self": false,
                "to_port": 4789
              },
              {
                "cidr_blocks": [
                  "10.100.0.0/16"
                ],
                "description": "Docker swarm management",
                "from_port": 2377,
                "ipv6_cidr_blocks": [],
                "prefix_list_ids": [],
                "protocol": "tcp",
                "security_groups": [],
                "self": false,
                "to_port": 2377
              }
            ],
            "name": "docker",
            "name_prefix": null,
            "owner_id": "569484333419",
            "revoke_rules_on_delete": false,
            "tags": {
              "Name": "docker-swarm Docker"
            },
            "timeouts": {
              "create": "2m",
              "delete": "2m"
            },
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoxMjAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwfSwic2NoZW1hX3ZlcnNpb24iOiIxIn0="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_sns_topic",
      "name": "alarms",
      "provider": "provider.aws",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "application_failure_feedback_role_arn": "",
            "application_success_feedback_role_arn": "",
            "application_success_feedback_sample_rate": null,
            "arn": "arn:aws:sns:us-east-1:569484333419:docker-swarm-alarms",
            "delivery_policy": "",
            "display_name": "",
            "http_failure_feedback_role_arn": "",
            "http_success_feedback_role_arn": "",
            "http_success_feedback_sample_rate": null,
            "id": "arn:aws:sns:us-east-1:569484333419:docker-swarm-alarms",
            "kms_master_key_id": "",
            "lambda_failure_feedback_role_arn": "",
            "lambda_success_feedback_role_arn": "",
            "lambda_success_feedback_sample_rate": null,
            "name": "docker-swarm-alarms",
            "name_prefix": null,
            "policy": "{\"Version\":\"2008-10-17\",\"Id\":\"__default_policy_ID\",\"Statement\":[{\"Sid\":\"__default_statement_ID\",\"Effect\":\"Allow\",\"Principal\":{\"AWS\":\"*\"},\"Action\":[\"SNS:GetTopicAttributes\",\"SNS:SetTopicAttributes\",\"SNS:AddPermission\",\"SNS:RemovePermission\",\"SNS:DeleteTopic\",\"SNS:Subscribe\",\"SNS:ListSubscriptionsByTopic\",\"SNS:Publish\",\"SNS:Receive\"],\"Resource\":\"arn:aws:sns:us-east-1:569484333419:docker-swarm-alarms\",\"Condition\":{\"StringEquals\":{\"AWS:SourceOwner\":\"569484333419\"}}}]}",
            "sqs_failure_feedback_role_arn": "",
            "sqs_success_feedback_role_arn": "",
            "sqs_success_feedback_sample_rate": null,
            "tags": null
          },
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_subnet",
      "name": "managers",
      "each": "list",
      "provider": "provider.aws",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-009f7db49a1b27527",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1a",
            "availability_zone_id": "use1-az6",
            "cidr_block": "10.100.10.0/24",
            "id": "subnet-009f7db49a1b27527",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1a"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 1,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-048f7c9eda782262a",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1b",
            "availability_zone_id": "use1-az1",
            "cidr_block": "10.100.11.0/24",
            "id": "subnet-048f7c9eda782262a",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1b"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 2,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0e5abf73a4eada2bc",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1c",
            "availability_zone_id": "use1-az2",
            "cidr_block": "10.100.12.0/24",
            "id": "subnet-0e5abf73a4eada2bc",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1c"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 3,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0037169cfa4093d48",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1d",
            "availability_zone_id": "use1-az4",
            "cidr_block": "10.100.13.0/24",
            "id": "subnet-0037169cfa4093d48",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1d"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 4,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0bff3e5ad68efb61d",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1e",
            "availability_zone_id": "use1-az3",
            "cidr_block": "10.100.14.0/24",
            "id": "subnet-0bff3e5ad68efb61d",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1e"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 5,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0178c58133dbfb80a",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1f",
            "availability_zone_id": "use1-az5",
            "cidr_block": "10.100.15.0/24",
            "id": "subnet-0178c58133dbfb80a",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm managers us-east-1f"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "aws_subnet",
      "name": "workers",
      "each": "list",
      "provider": "provider.aws",
      "instances": [
        {
          "index_key": 0,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-07be5f3106a81967c",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1a",
            "availability_zone_id": "use1-az6",
            "cidr_block": "10.100.110.0/24",
            "id": "subnet-07be5f3106a81967c",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1a"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 1,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0feeda4742873bb38",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1b",
            "availability_zone_id": "use1-az1",
            "cidr_block": "10.100.111.0/24",
            "id": "subnet-0feeda4742873bb38",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1b"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 2,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0528a102948f990a9",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1c",
            "availability_zone_id": "use1-az2",
            "cidr_block": "10.100.112.0/24",
            "id": "subnet-0528a102948f990a9",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1c"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 3,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-07fc208faa1109c20",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1d",
            "availability_zone_id": "use1-az4",
            "cidr_block": "10.100.113.0/24",
            "id": "subnet-07fc208faa1109c20",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1d"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 4,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-009df2e98043980ac",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1e",
            "availability_zone_id": "use1-az3",
            "cidr_block": "10.100.114.0/24",
            "id": "subnet-009df2e98043980ac",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1e"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        },
        {
          "index_key": 5,
          "schema_version": 1,
          "attributes": {
            "arn": "arn:aws:ec2:us-east-1:569484333419:subnet/subnet-0c6adf12e286bf68c",
            "assign_ipv6_address_on_creation": false,
            "availability_zone": "us-east-1f",
            "availability_zone_id": "use1-az5",
            "cidr_block": "10.100.115.0/24",
            "id": "subnet-0c6adf12e286bf68c",
            "ipv6_cidr_block": "",
            "ipv6_cidr_block_association_id": "",
            "map_public_ip_on_launch": true,
            "outpost_arn": "",
            "owner_id": "569484333419",
            "tags": {
              "Name": "docker-swarm workers us-east-1f"
            },
            "timeouts": null,
            "vpc_id": "vpc-08e7f421041da4651"
          },
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjo2MDAwMDAwMDAwMDAsImRlbGV0ZSI6MTIwMDAwMDAwMDAwMH0sInNjaGVtYV92ZXJzaW9uIjoiMSJ9"
        }
      ]
    },
    {
      "mode": "managed",
      "type": "tls_cert_request",
      "name": "daemons",
      "each": "list",
      "provider": "provider.tls",
      "instances": []
    }
  ]
}
